# -*- coding: utf-8 -*-
"""emnist_training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zOA0BJRrcOszo9kkTx5WIME5Ka7DfW0u
"""

from torchvision import datasets, transforms
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
import matplotlib.pyplot as plt # for plotting
import torch.optim as optim
import numpy as np
from torch.utils.data.sampler import SubsetRandomSampler
from plate_data_loader import *
from plateToCharactersModule import *
from torch.utils.data import TensorDataset, DataLoader

# define a 2-layer artificial neural network
class Emnist_net2(nn.Module):
    def __init__(self):
        super(Emnist_net, self).__init__()
        self.name = "ANN"
        self.layer1 = nn.Linear(28 * 28, 450)
        self.layer2 = nn.Linear(450, 47)

    def forward(self, img):
        flattened = img.view(-1, 28 * 28)
        activation1 = self.layer1(flattened)
        activation1 = F.relu(activation1)
        activation2 = self.layer2(activation1)
        return activation2



# define a 2-layer artificial neural network
class Emnist_net(nn.Module):
    def __init__(self):
        super(Emnist_net, self).__init__()
        self.name = "CNN"
        self.conv1 = nn.Conv2d(1, 5, 5) #input channel 1, output channel 5 240*240*5
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d
        self.fc1 = nn.Linear(120*120*5, 47)
    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = x.view(-1, 12*12*5)
        x = self.fc1(x)
        return x

class OCV_net(nn.Module):
    def __init__(self):
        super(OCV_net, self).__init__()
        self.name = "CNN"
        self.conv1 = nn.Conv2d(1, 5, 5) #input channel 1, output channel 5 276*276*5
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(5, 10, 5) # 134*134*10
        self.fc1 = nn.Linear(67*67*10, 2500)
        self.fc2 = nn.Linear(2500,36)
    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 67*67*10)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

o_net = OCV_net()

def get_data_loader(batch_size, split):

  torch.manual_seed(1) # set the random seed
  emnist_data = datasets.EMNIST('data', train= True, split = "balanced", download = True,transform=transforms.ToTensor())
#  print(len(emnist_data))
#  count = np.zeros(47)
#  for data, label in emnist_data:
#    count[label]+=1
#  print(np.max(count), np.min(count))
  np.random.seed(1000)
  indice =np.arange(len(emnist_data)) 
  np.random.shuffle(indice)
  split_idx = int(len(emnist_data)*split)
  train_index = indice[:split_idx]
  val_index = indice[split_idx:]
  train_sampler = SubsetRandomSampler(train_index)
  train_loader = torch.utils.data.DataLoader(emnist_data, batch_size=batch_size,   num_workers=0, sampler=train_sampler) 
  val_sampler = SubsetRandomSampler(val_index)
  val_loader = torch.utils.data.DataLoader(emnist_data, batch_size=batch_size,
                                            num_workers=0, sampler=val_sampler)
  testset = datasets.EMNIST('data', train= False, split = "balanced", download = True,transform=transforms.ToTensor())
  # Get the list of indices to sample from
  #test_sampler = SubsetRandomSampler(np.arange(len(emnist_data)))
  test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                            num_workers=0)#, sampler = test_sampler
  return train_loader, val_loader, test_loader

tr,v, te = get_data_loader(1, 0.7)
print(len(tr), len(v), len(te))

def get_accuracy(model, data_loader):
    correct = 0
    total = 0
    for imgs, labels in data_loader:
       
        if use_cuda and torch.cuda.is_available():
          imgs = imgs.cuda()
          labels = labels.cuda()

        output = model(imgs)
        #select index with maximum prediction score
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(labels.view_as(pred)).sum().item()
        total += imgs.shape[0]
    return correct / total

def train(model, lr, batch_size, epochs, split = 0.8, openCV = False):
  if openCV :
      train_loader = OpenCV_loader(train_img, train_lab)
      val_loader = OpenCV_loader(val_img, val_lab)
      test_loader = OpenCV_loader(test_img, test_lab)
  else:
      train_loader, val_loader, test_loader = get_data_loader(batch_size, split)
  criterion = nn.CrossEntropyLoss()
  optimizer = optim.Adam(model.parameters(), lr=lr)
  epoch = []
  train_acc, val_acc, losses = [],[],[]
  for epo in range(epochs):
    for imgs, labels in iter(train_loader):
      #print(labels.shape)
      if use_cuda and torch.cuda.is_available():
        imgs = imgs.cuda()
        labels = labels.cuda()
        model.cuda()

      out = model(imgs)             # forward pass
      #print(type(out),type(labels))
      loss = criterion(out, labels) # compute the total loss
      loss.backward()               # backward pass (compute parameter updates)
      optimizer.step()              # make the updates for each parameter
      optimizer.zero_grad()
      losses.append(loss)
    epoch.append(epo)
    train_acc.append(get_accuracy(model, train_loader))
    val_acc.append(get_accuracy(model, val_loader))
    print("epoch:",epo, train_acc[-1], val_acc[-1])
  model_path = "model_{0}_bs{1}_lr{2}_epoch{3}".format(e_net.name,
                                                   batch_size,
                                                   lr,
                                                   epochs)
  dirname = "C:/Users/bowen/Documents/APS360/project/APS360-project/APS360-Project/Model/"
  model_path = os.path.join(dirname,model_path)
  torch.save(model.state_dict(), model_path)

  fig, axs = plt.subplots(2, 1, constrained_layout=True)
  axs[0].plot(losses, label="Train")
  axs[0].set_title("Loss Curve learning rate:{}, epo:{}, batch_size:{}".format(lr, epo, batch_size))
  axs[0].set_xlabel("Epoch")
  axs[0].set_ylabel("Loss")

  axs[1].set_title("Accuracy Curve learning rate:{}, epo:{}, batch_size:{}".format(lr, epo, batch_size))
  axs[1].plot(epoch, train_acc, label="Train")
  axs[1].plot(epoch, val_acc, label="Validation")
  axs[1].set_xlabel("Epoch")
  axs[1].set_ylabel("Accuracy")
  plt.legend(loc='best')
  plt.show()
  return losses, train_acc, val_acc

class Dataloader2(Dataset):
    def __init__(self, csv_path, transform = None, datasetType = 0, one_hot = True):
        """
        Args:
            csv_path (string): path to csv file
            transform: pytorch transforms for transform
            test: whether to generate train/test loader
            one_hot: whether the label is one-hot list or string of label
        """
        
        # One hot list as label?
        self.one_hot = one_hot

        # Read the csv file
        pf = pd.read_csv(csv_path)

        # Filter the data:

        # Only use 7 digits plates as datasets
        sevenLengthPf = pf[pf.iloc[:, 2].str.len() == 7]

        # Load train/test data
        self.datasetType = datasetType
        
        if self.datasetType == 0: # Train
            tmp = sevenLengthPf[sevenLengthPf.iloc[:, 3] == 1]
            self.data_info = tmp.iloc[:int(3*len(tmp)/4), :]

        elif self.datasetType == 1: # Val
            tmp = sevenLengthPf[sevenLengthPf.iloc[:, 3] == 1]
            self.data_info = tmp.iloc[int(3*len(tmp)/4):, :]
        
        elif self.datasetType == 2: # Test
            self.data_info = sevenLengthPf[sevenLengthPf.iloc[:, 3] == 0]

        # First column contains the image paths
        self.paths = np.asarray(self.data_info.iloc[:, 1])

        # Second column is the labels
        self.labels = np.asarray(self.data_info.iloc[:, 2])

        # Third column is for an train Boolean
        self.trainBools = np.asarray(self.data_info.iloc[:, 3])

        # Calculate len
        self.data_len = len(self.data_info.index)

        # Transform function
        self.transform = transform

        # Transform to tensor
        self.to_tensor = transforms.ToTensor()
    
        
    def __getitem__(self, index):

        # Get image name from the pandas df
        imageName = self.paths[index]
        dirname = "C:/Users/bowen/Documents/APS360/project/APS360-project/APS360-Project/Model/" #os.path.dirname(__file__)os.path.dirname(__file__)
        image_path = os.path.join(dirname, '..//..//..//2017-IWT4S-CarsReId_LP-dataset', imageName)

        # Open image
        img = Image.open(image_path)
        
        # Transform image to tensor
        if self.transform !=None:
            img = self.transform(img)
        imgTensor = self.to_tensor(img)
        
        # Get license plate number
        if(self.one_hot == False):
            label = self.labels[index]
        else:
            # Use one_hot
            # creating initial dataframe
            alphaNumerical_Types = ('0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z')
            listOfPlate = []
            for alphaNumerical in self.labels[index]:
                
                place = alphaNumerical_Types.index(alphaNumerical)
                if place >=0 and place <= 35:
                    # oneHotList = [0] * 36
                    # oneHotList[place] = 1
                    listOfPlate.append(place)
                    
            # import pdb; pdb.set_trace()
            ident = torch.eye(36)
            label = ident[torch.tensor(listOfPlate)]

            # label = listOfPlate

        return (imgTensor, label)

    def __len__(self):
        return self.data_len


def load_single_char(Dataloader2, data_ratio):
    seven_digit_plate_count=0
    data_list, label_list = [], []
               # Get image name from the pandas df
    num_data = len(Dataloader2)
    for index in range(int(num_data*data_ratio)):
        if len(Dataloader2.labels[index]) == 7 :
            seven_digit_plate_count += 1
        imageName = Dataloader2.paths[index]
        dirname = "C:/Users/bowen/Documents/APS360/project/APS360-project/APS360-Project/Model/" #os.path.dirname(__file__)
        image_path = os.path.join(dirname, '..//..//..//2017-IWT4S-CarsReId_LP-dataset', imageName)
        alphaNumerical_Types = ('0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z')
            # Open image
        img = cv2.imread(image_path)
        skip=False
        try:
            outputs = slicePic(img)
        except:
            skip=True
        if (skip==False):
        # print out images
            if (len(outputs)==7):
                count = 0
                for image in outputs:
                    data_list.append(image)
                    label_list.append(alphaNumerical_Types.index(list( Dataloader2.labels[index])[count]))
                    count=count+1
    print("total number of 7 number plates loaded {}".format(len(data_list) / 7))
    print("OpenCV success rate on all 7 cropping: {}".format(len(data_list) / 7 / seven_digit_plate_count))
    return data_list, label_list

use_cuda = False
print(torch.cuda.is_available())

#Below is extract images from opencv

# load csv
header = ['track_id', 'image_path', 'lp', 'train']
dirname = "C:/Users/bowen/Documents/APS360/project/APS360-project/APS360-Project/Model/" #os.path.dirname(__file__)
filename = os.path.join(dirname, '..//..//..//2017-IWT4S-CarsReId_LP-dataset//trainVal.csv')

data_transform = transforms.Compose([transforms.Resize((50,140))])
    
train_data = Dataloader2(filename, transform=data_transform, datasetType = 0, one_hot = False)
val_data = Dataloader2(filename, transform=data_transform, datasetType = 1, one_hot = False)
test_data = Dataloader2(filename, transform=data_transform, datasetType = 2, one_hot = False)
print("whole plate train data : {}, valid data: {}, test data {}".format(len(train_data), len(val_data), len(test_data)))

#76032

data_ratio = 0.2
train_ratio=0.2
val_ratio = 0.5
test_ratio = 0.1
tr_d, tr_l = load_single_char(train_data, train_ratio)
v_d, v_l = load_single_char(val_data, val_ratio)
ts_d, ts_l = load_single_char(test_data, test_ratio)

def list_suffle_to_np(data_list, label_list):
    #print(label_list[:10])
    np_img = np.array(data_list)
    #print(np_img.shape)
    np_lab = np.array(label_list)
    np.random.seed(1000)  # Fixed numpy random seed for reproducible shuffling
    img_idx = np.arange(len(data_list))
    np.random.shuffle(img_idx)
    np_img = np_img.take(img_idx,axis=0)
    np_lab = np_lab.take(img_idx,axis=0)
    #print(np_lab.shape)
    #print(np_lab[:10])
    return np_img, np_lab

train_img, train_lab = list_suffle_to_np(tr_d, tr_l)
val_img, val_lab = list_suffle_to_np(v_d, v_l)
test_img, test_lab = list_suffle_to_np(ts_d, ts_l)

# print(train_img.shape)
def OpenCV_loader(img, lab, batch_size = 32):
    img = torch.unsqueeze(torch.Tensor(img),1)
    lab = torch.LongTensor(lab)
    dataset = TensorDataset(img, lab)
    data_loader = DataLoader(dataset, batch_size=batch_size, num_workers=0)
    return data_loader
#Above is extract images from opencv keep it

#datat loader
train_loader = OpenCV_loader(train_img, train_lab, batch_size = 32)
val_loader = OpenCV_loader(val_img, val_lab, batch_size = 32)
test_loader = OpenCV_loader(test_img, test_lab, batch_size = 32)
losses, train_acc, valid_acc = train(o_net, lr= 0.0001, batch_size = 32, epochs = 10, split = 0.8, openCV=True)


e_net = Emnist_net()
model_path = "C:/Users/bowen/Documents/APS360/project/APS360-project/APS360-Project/Model/model_CNN_bs32_lr0.0001_epoch30_280"
state = torch.load(model_path)
e_net.load_state_dict(state)
print(get_accuracy(e_net, test_loader))

# i = 0
# for img, label in train_loader:
#     i+=1
#     plt.figure()
#     plt.imshow(img[0].squeeze(0))
#     out = e_net(img)
#     max_idx = torch.max(out, dim=1)[1]
#     print("prediction : {}, label {}".format(max_idx, label))
#     if i == 3:
#         break

    #print(torch.sum(max_inx == label))