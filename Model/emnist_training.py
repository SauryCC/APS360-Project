# -*- coding: utf-8 -*-
"""emnist_training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zOA0BJRrcOszo9kkTx5WIME5Ka7DfW0u
"""

from torchvision import datasets, transforms
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
import matplotlib.pyplot as plt # for plotting
import torch.optim as optim
import numpy as np
from torch.utils.data.sampler import SubsetRandomSampler

# define a 2-layer artificial neural network
class Emnist_net(nn.Module):
    def __init__(self):
        super(Emnist_net, self).__init__()
        self.name = "ANN"
        self.layer1 = nn.Linear(28 * 28, 450)
        self.layer2 = nn.Linear(450, 47)

    def forward(self, img):
        flattened = img.view(-1, 28 * 28)
        activation1 = self.layer1(flattened)
        activation1 = F.relu(activation1)
        activation2 = self.layer2(activation1)
        return activation2

e_net = Emnist_net()

# define a 2-layer artificial neural network
class Emnist_net(nn.Module):
    def __init__(self):
        super(Emnist_net, self).__init__()
        self.name = "CNN"
        self.conv1 = nn.Conv2d(1, 5, 5) #input channel 1, output channel 5 24*24*5
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(12*12*5, 47)
    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = x.view(-1, 12*12*5)
        x = self.fc1(x)
        return x

e_net = Emnist_net()

def get_data_loader(batch_size, split):

  torch.manual_seed(1) # set the random seed
  emnist_data = datasets.EMNIST('data', train= True, split = "balanced", download = True,transform=transforms.ToTensor())
#  print(len(emnist_data))
#  count = np.zeros(47)
#  for data, label in emnist_data:
#    count[label]+=1
#  print(np.max(count), np.min(count))
  np.random.seed(1000)
  indice =np.arange(len(emnist_data)) 
  np.random.shuffle(indice)
  split_idx = int(len(emnist_data)*split)
  train_index = indice[:split_idx]
  val_index = indice[split_idx:]
  train_sampler = SubsetRandomSampler(train_index)
  train_loader = torch.utils.data.DataLoader(emnist_data, batch_size=batch_size,   num_workers=0, sampler=train_sampler) 
  val_sampler = SubsetRandomSampler(val_index)
  val_loader = torch.utils.data.DataLoader(emnist_data, batch_size=batch_size,
                                            num_workers=0, sampler=val_sampler)
  testset = datasets.EMNIST('data', train= False, split = "balanced", download = True,transform=transforms.ToTensor())
  # Get the list of indices to sample from
  #test_sampler = SubsetRandomSampler(np.arange(len(emnist_data)))
  test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                            num_workers=0)#, sampler = test_sampler
  return train_loader, val_loader, test_loader

tr,v, te = get_data_loader(1, 0.7)
print(len(tr), len(v), len(te))

def get_accuracy(model, data_loader):
    correct = 0
    total = 0
    for imgs, labels in data_loader:
       
        if use_cuda and torch.cuda.is_available():
          imgs = imgs.cuda()
          labels = labels.cuda()

        output = model(imgs)
        #select index with maximum prediction score
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(labels.view_as(pred)).sum().item()
        total += imgs.shape[0]
    return correct / total

def train(model, lr, batch_size, epochs, split = 0.8):
  train_loader, val_loader, test_loader = get_data_loader(batch_size, split)
  criterion = nn.CrossEntropyLoss()
  optimizer = optim.Adam(model.parameters(), lr=lr)
  epoch = []
  train_acc, val_acc, losses = [],[],[]
  for epo in range(epochs):
    for imgs, labels in iter(train_loader):
      if use_cuda and torch.cuda.is_available():
        imgs = imgs.cuda()
        labels = labels.cuda()
        model.cuda()

      out = model(imgs)             # forward pass
      loss = criterion(out, labels) # compute the total loss
      loss.backward()               # backward pass (compute parameter updates)
      optimizer.step()              # make the updates for each parameter
      optimizer.zero_grad()
      losses.append(loss)
    epoch.append(epo)
    train_acc.append(get_accuracy(model, train_loader))
    val_acc.append(get_accuracy(model, val_loader))
    print("epoch:",epo, train_acc[-1], val_acc[-1])
  model_path = "model_{0}_bs{1}_lr{2}_epoch{3}".format(e_net.name,
                                                   batch_size,
                                                   lr,
                                                   epochs)
  torch.save(e_net.state_dict(), model_path)
  plt.title("Training Curve learning rate:{}, epo:{}, batch_size:{}".format(lr, epo, batch_size))
  plt.plot(losses, label="Train")
  plt.xlabel("Epoch")
  plt.ylabel("Loss")
  plt.show()

  plt.title("Training Curve learning rate:{}, epo:{}, batch_size:{}".format(lr, epo, batch_size))
  plt.plot(epoch, train_acc, label="Train")
  plt.plot(epoch, val_acc, label="Validation")
  plt.xlabel("Epoch")
  plt.ylabel("Accuracy")
  plt.legend(loc='best')
  plt.show()

use_cuda = True
print(torch.cuda.is_available())
train(e_net,lr = 0.0001, batch_size = 32, epochs = 30)

!unzip '/content/drive/My Drive/Colab Notebooks/APS360 LAB/project/imgs.zip' -d '/root/datasets'

data_dir = "/root/datasets"
data_transform = transforms.Compose([transforms.Resize((28,28)), transforms.Grayscale(num_output_channels=1),
                                      transforms.ToTensor()])
test_set = datasets.ImageFolder(data_dir, transform=data_transform)
test_loader = torch.utils.data.DataLoader(test_set, batch_size=1,
                                               num_workers=0, shuffle=True)
print(len(test_loader))
for img, label in test_loader:
#  plt.imshow(img[0][0])
  print(label)
  out = e_net(img.cuda())
  print(torch.max(out,dim =1))

get_accuracy(e_net, test_loader)

import shutil
shutil.rmtree(data_dir + '/imgs')

batch_size = 1
split = 0.7
train_loader, val_loader, test_loader = get_data_loader(batch_size, split)
#get_accuracy(e_net, test_loader)

get_accuracy(e_net, test_loader)